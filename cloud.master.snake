"""
This Snakefile downloads sample bams from the cloud 
and maps the sample by calling cloud.mapper.snake
"""

import os
import sys
import pysam
from subprocess import CalledProcessError
from subprocess import check_output
import pandas as pd

import boto.dynamodb

SNAKEMAKE_DIR = os.path.dirname(workflow.snakefile)

from snakemake.remote.S3 import RemoteProvider as S3RemoteProvider

S3 = S3RemoteProvider(access_key_id=os.environ["AWS_ACCESS_KEY_ID"], secret_access_key=os.environ["AWS_SECRET_ACCESS_KEY"])
conn = boto.dynamodb.connect_to_region("us-east-1", 
                                       aws_access_key_id=os.environ["AWS_ACCESS_KEY_ID"], 
                                       aws_secret_access_key=os.environ["AWS_SECRET_ACCESS_KEY"])

INSTANCE_IP = check_output(["curl", "http://169.254.169.254/latest/meta-data/public-ipv4"])

shell.executable("/bin/bash")
shell.prefix("set -euo pipefail; ")

if config == {}:
    configfile: "cloud.config.yaml"

MANIFEST = config["manifest"]
REFERENCE = config["reference"]
MASKED_REF = config[REFERENCE]["masked_ref"]
CONTIGS_FILE = config[REFERENCE]["contigs"]

BAM_PARTITIONS = config["bam_partitions"]
UNMAPPED_PARTITIONS = config["unmapped_partitions"]
if UNMAPPED_PARTITIONS == -1:
    UNMAPPED_PARTITIONS = max(BAM_PARTITIONS // 500, 1)
MAX_BP = config["max_bp_in_mem"]

TMPDIR = config["tmpdir"]
LIVE_MERGE = config["live_merge"]
CLEAN_TEMP_FILES = config["clean_temp_files"]

BUCKET = config["bucket"]

if not os.path.exists("log"):
    os.makedirs("log")

CONTIGS = {}

with open(CONTIGS_FILE, "r") as reader:
    for line in reader:
        contig, size = line.rstrip().split()
        CONTIGS[contig] = int(size)

SAMPLES = pd.read_table(MANIFEST)

localrules: all

rule all:
    input:  S3.remote(expand("%s/mapping/{sample}/{sample}/wssd_out_file" % BUCKET, sample = SAMPLES.sn)), \
            expand("cleaned/{sample}.txt", sample = SAMPLES.sn)

rule clean:
    input: S3.remote("%s/mapping/{sample}/{sample}/wssd_out_file" % BUCKET)
    output: touch("cleaned/{sample}.txt")
    run:
        dynamo_table = conn.get_table("SimonsRDTracking")
        sample_item = dynamo_table.get_item(hash_key = wildcards.sample)
        sample_item["finished"] = 1
        sample_item.put()
        #'aws dynamodb update-item --table-name SimonsRDTracking --key {wildcards.sample} --update-expression SET finished 1'
        shell('aws s3 rm s3://{BUCKET}/mapping/{wildcards.sample}/{wildcards.sample}/ --recursive --exclude "wssd_out_file"')

rule map_sample:
    input: "bam/{sample}.bam", "bam/{sample}.bai", "MRSFASTULTRA_INDEXED"
    output: S3.remote("%s/mapping/{sample}/{sample}/wssd_out_file" % BUCKET)
    params: sge_opts = ""
    benchmark: "benchmarks/wssd_out/{sample}.txt"
    resources: cores=40, mem=156
    priority: 20
    shell:
        "snakemake -s cloud.mapper.snake --config sample={wildcards.sample} workdir={SNAKEMAKE_DIR} -j 30 --resources mem=148 -w 30"

rule download_sample:
    input: lambda wildcards: S3.remote(SAMPLES.ix[SAMPLES.sn == wildcards.sample, "bam"]),
           lambda wildcards: S3.remote(SAMPLES.ix[SAMPLES.sn == wildcards.sample, "index"]),
           "MRSFASTULTRA_INDEXED"
    output: temp("bam/{sample}.bam"),
            temp("bam/{sample}.bai")
    resources: cores=1
    priority: 10
    run:
        bam = SAMPLES.ix[SAMPLES.sn == wildcards.sample, "bam"].values[0]
        bai = SAMPLES.ix[SAMPLES.sn == wildcards.sample, "index"].values[0]
        shell("mv {bam} {output[0]}")
        shell("mv {bai} {output[1]}")
        shell("touch {bam}")
        shell("touch {bai}")
        shell("touch {output}")
        dynamo_table = conn.get_table("SimonsRDTracking")
        #shell("aws dynamodb update-item --table-name SimonsRDTracking --key {wildcards.sample} --update-expression SET instanceID $HOSTNAME")
        sample_item = dynamo_table.get_item(hash_key = wildcards.sample)
        sample_item["instanceIP"] = INSTANCE_IP
        sample_item.put()
        #shell("""aws dynamodb update-item --table-name SimonsRDTracking --key '{{"wssdID": {{"S": "{wildcards.sample}"}}}}' --update-expression "SET instanceID :id" --expression-attribute-values '{{":id": {{"S": "{INSTANCE_IP}"}}}}'""")    

rule check_index:
    input: MASKED_REF
    output: touch("MRSFASTULTRA_INDEXED"), temp(".mrsfast_index_test_output.txt")
    params: sge_opts = ""
    run:
        try:
            shell("mrsfast --search {input[0]} --seq dummy.fq > {output[1]}")
        except CalledProcessError as e:
            sys.exit("Reference %s was not indexed with the current version of mrsfastULTRA. Please reindex." % input[0])

rule make_chunker:
    input: "src/chunker_cascade.cpp", "Makefile"
    output: "bin/bam_chunker_cascade"
    params: sge_opts = ""
    shell:
        "make"
